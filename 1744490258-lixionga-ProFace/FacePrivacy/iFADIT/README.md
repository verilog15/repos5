# iFADIT: Invertible Face Anonymization via Disentangled Identity Transformation



# Introduction
Face capture has become a ubiquitous activity to support various utility scenarios, but has also raised global privacy concerns due to the extensive collection and abuse of individuals facial data. Practical solutions for protecting facial privacy often rely on simplified image obfuscations to suppress facial details, but are prone to deep reconstruction attacks and identity inference by machine vision. In this paper, we explore a disentangled methodology that decouples the sensitive identity information from the image and accomplishes face anonymization by transforming the decoupled identity in a secure and reversible manner. To this end, a secure invertible neural network is adopted to perform secure identity transformation and reconstruction. A dedicated dual-phase training strategy is devised to optimize the disentanglement and the transformation processes progressively. 
Official Implementation of the paper *iFADIT: Invertible Face Anonymization via Disentangled Identity Transformation* for evaluation.


## Setup

```
conda env create -f environment.yaml
pip install -r requirements.txt
```


<!--## Training

### Preparing the Dataset

The dataset is comprised of StyleGAN-generated images and W latent codes, both are generated from a single
StyleGAN model.

We also use real images from FFHQ to evaluate quality at test time.

The dataset is assumed to be in the following structure:

| Path | Description
| :--- | :---
| base directory | Directory for all datasets
| &boxvr;&nbsp; real | FFHQ image dataset
| &boxvr;&nbsp; dataset_N | dataset for resolution NxN
| &boxv;&nbsp; &boxvr;&nbsp; images | images generated by StyleGAN
| &boxv;&nbsp; &boxur;&nbsp; ws | W latent codes generated by StyleGAN

To generate the `dataset_N` directory, run:

```
cd utils\
python generate_fake_data.py \ 
    --resolution N \
    --batch_size BATCH_SIZE \
    --output_path OUTPUT_PATH \
    --pretrained_models_path PRETRAINED_MODELS_PATH \
    --num_images NUM_IMAGES \
    --gpu GPU
```

It will generate an image dataset in similar format to FFHQ.

### Start training

To train the model as done in the paper

```
python main.py
    NAME
    --resolution N
    --pretrained_models_path PRETRAINED_MODELS_PATH
    --dataset BASE_DATASET_DIR
    --batch_size BATCH_SIZE
    --cross_frequency 3
    --train_data_size 70000
    --results_dir RESULTS_DIR        
```

Please run `python main.py -h` for more details.
-->
## Inference

```
python test/test.py 

```

## Checkpoints

Our pretrained [checkpoint](https://drive.google.com/drive/folders/1XIE9_3LXKiIJNdtroyZvwCKaKnu-x12O?usp=sharing) is also available.
